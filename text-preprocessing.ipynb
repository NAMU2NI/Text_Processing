{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8841,"sourceType":"datasetVersion","datasetId":4133},{"sourceId":2642942,"sourceType":"datasetVersion","datasetId":1607065}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-08T08:55:05.906862Z","iopub.execute_input":"2024-02-08T08:55:05.907392Z","iopub.status.idle":"2024-02-08T08:55:07.099852Z","shell.execute_reply.started":"2024-02-08T08:55:05.907353Z","shell.execute_reply":"2024-02-08T08:55:07.099000Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chat-slang-abbreviations-acronyms/slang/slang.pkl\n/kaggle/input/chat-slang-abbreviations-acronyms/slang/slang.csv\n/kaggle/input/chat-slang-abbreviations-acronyms/slang/slang.txt\n/kaggle/input/chat-slang-abbreviations-acronyms/slang/slang.json\n/kaggle/input/customer-support-on-twitter/sample.csv\n/kaggle/input/customer-support-on-twitter/twcs/twcs.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/customer-support-on-twitter/twcs/twcs.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:07.101605Z","iopub.execute_input":"2024-02-08T08:55:07.102533Z","iopub.status.idle":"2024-02-08T08:55:25.332939Z","shell.execute_reply.started":"2024-02-08T08:55:07.102502Z","shell.execute_reply":"2024-02-08T08:55:25.331519Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:25.334170Z","iopub.execute_input":"2024-02-08T08:55:25.334541Z","iopub.status.idle":"2024-02-08T08:55:25.355174Z","shell.execute_reply.started":"2024-02-08T08:55:25.334498Z","shell.execute_reply":"2024-02-08T08:55:25.354224Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   tweet_id   author_id  inbound                      created_at  \\\n0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n\n                                                text response_tweet_id  \\\n0  @115712 I understand. I would like to assist y...                 2   \n1      @sprintcare and how do you propose we do that               NaN   \n2  @sprintcare I have sent several private messag...                 1   \n3  @115712 Please send us a Private Message so th...                 3   \n4                                 @sprintcare I did.                 4   \n\n   in_response_to_tweet_id  \n0                      3.0  \n1                      1.0  \n2                      4.0  \n3                      5.0  \n4                      6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 I understand. I would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare I have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 Please send us a Private Message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare I did.</td>\n      <td>4</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Convert the tweets to lower case ","metadata":{}},{"cell_type":"code","source":"df['text']= df['text'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:25.357639Z","iopub.execute_input":"2024-02-08T08:55:25.357949Z","iopub.status.idle":"2024-02-08T08:55:26.820514Z","shell.execute_reply.started":"2024-02-08T08:55:25.357924Z","shell.execute_reply":"2024-02-08T08:55:26.818726Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Punctuation Removal","metadata":{}},{"cell_type":"code","source":"import string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:26.822337Z","iopub.execute_input":"2024-02-08T08:55:26.822678Z","iopub.status.idle":"2024-02-08T08:55:26.831052Z","shell.execute_reply.started":"2024-02-08T08:55:26.822651Z","shell.execute_reply":"2024-02-08T08:55:26.829286Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"def remove_punctuation (text): \n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:26.833041Z","iopub.execute_input":"2024-02-08T08:55:26.835073Z","iopub.status.idle":"2024-02-08T08:55:26.843583Z","shell.execute_reply.started":"2024-02-08T08:55:26.835029Z","shell.execute_reply":"2024-02-08T08:55:26.842415Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## Applying the Punctuation free function for the \ndf['text_pc'] =  df['text'].apply(lambda x: remove_punctuation(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:55:26.845476Z","iopub.execute_input":"2024-02-08T08:55:26.847083Z","iopub.status.idle":"2024-02-08T08:56:04.963846Z","shell.execute_reply.started":"2024-02-08T08:55:26.847044Z","shell.execute_reply":"2024-02-08T08:56:04.963103Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Function for Abbreviations ","metadata":{}},{"cell_type":"code","source":"## Read the Abbreviations from the Text and Convert it back into the \n\ndef read_text_file(filename):\n    data = {}  # Create an empty dictionary to store key-value pairs\n    with open(filename, 'r') as file:\n        for line in file:\n            # Split each line by '=' to separate key and value\n            key, value = line.strip().split('\t')\n            # Store key-value pair in the dictionary\n            data[key] = value\n    return data\n\nfilename = '/kaggle/input/chat-slang-abbreviations-acronyms/slang/slang.txt'\ndata_dict = read_text_file(filename)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:04.965242Z","iopub.execute_input":"2024-02-08T08:56:04.965788Z","iopub.status.idle":"2024-02-08T08:56:04.987121Z","shell.execute_reply.started":"2024-02-08T08:56:04.965736Z","shell.execute_reply":"2024-02-08T08:56:04.985687Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## Function for replacing the Slang words with full Text \n\ndef chat_conversion(text):\n    new_text=[]\n    for w in text.split():\n        if w.upper() in data_dict:\n            new_text.append(data_dict[w.upper()])\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:04.988445Z","iopub.execute_input":"2024-02-08T08:56:04.988787Z","iopub.status.idle":"2024-02-08T08:56:04.994988Z","shell.execute_reply.started":"2024-02-08T08:56:04.988742Z","shell.execute_reply":"2024-02-08T08:56:04.993749Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"## Applying the Punctuation free function for the \ndf['text_pc_sl'] =  df['text_pc'].apply(lambda x: chat_conversion(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:04.996141Z","iopub.execute_input":"2024-02-08T08:56:04.996499Z","iopub.status.idle":"2024-02-08T08:56:20.235748Z","shell.execute_reply.started":"2024-02-08T08:56:04.996453Z","shell.execute_reply":"2024-02-08T08:56:20.234522Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Stop words Removal ","metadata":{}},{"cell_type":"code","source":"import nltk\n#Stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:20.239104Z","iopub.execute_input":"2024-02-08T08:56:20.239453Z","iopub.status.idle":"2024-02-08T08:56:21.463367Z","shell.execute_reply.started":"2024-02-08T08:56:20.239422Z","shell.execute_reply":"2024-02-08T08:56:21.462312Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(text):\n    new_text = []\n    for word in text.split():\n            if word in stopwords:\n                new_text.append(\"\")\n            else :\n                new_text.append(word)     \n    return(\" \".join(new_text))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:21.464512Z","iopub.execute_input":"2024-02-08T08:56:21.465399Z","iopub.status.idle":"2024-02-08T08:56:21.472443Z","shell.execute_reply.started":"2024-02-08T08:56:21.465369Z","shell.execute_reply":"2024-02-08T08:56:21.471151Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## Sanity check on the data \nt = ' We are learning this that i am NLP course'\nprint(t)\nprint(\"after the funciton\")\nremove_stopwords(t)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:21.473847Z","iopub.execute_input":"2024-02-08T08:56:21.474200Z","iopub.status.idle":"2024-02-08T08:56:21.487590Z","shell.execute_reply.started":"2024-02-08T08:56:21.474116Z","shell.execute_reply":"2024-02-08T08:56:21.486580Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":" We are learning this that i am NLP course\nafter the funciton\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'We  learning     NLP course'"},"metadata":{}}]},{"cell_type":"code","source":"## Applying the Punctuation free function for the \ndf['text_pc_sl_sw'] =  df['text_pc_sl'].apply(lambda x: remove_stopwords(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:56:21.489164Z","iopub.execute_input":"2024-02-08T08:56:21.489446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['text_pc_sl_sw','text_pc_sl']].head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:20:58.041141Z","iopub.execute_input":"2024-02-08T09:20:58.041842Z","iopub.status.idle":"2024-02-08T09:20:58.060111Z","shell.execute_reply.started":"2024-02-08T09:20:58.041802Z","shell.execute_reply":"2024-02-08T09:20:58.059238Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   tweet_id   author_id  inbound                      created_at  \\\n0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n5         6  sprintcare    False  Tue Oct 31 21:46:24 +0000 2017   \n6         8      115712     True  Tue Oct 31 21:45:10 +0000 2017   \n7        11  sprintcare    False  Tue Oct 31 22:10:35 +0000 2017   \n8        12      115713     True  Tue Oct 31 22:04:47 +0000 2017   \n9        15  sprintcare    False  Tue Oct 31 20:03:31 +0000 2017   \n\n                                                text response_tweet_id  \\\n0  @115712 i understand. i would like to assist y...                 2   \n1      @sprintcare and how do you propose we do that               NaN   \n2  @sprintcare i have sent several private messag...                 1   \n3  @115712 please send us a private message so th...                 3   \n4                                 @sprintcare i did.                 4   \n5  @115712 can you please send us a private messa...               5,7   \n6          @sprintcare is the worst customer service            9,6,10   \n7  @115713 this is saddening to hear. please shoo...               NaN   \n8  @sprintcare you gonna magically change your co...          11,13,14   \n9  @115713 we understand your concerns and we'd l...                12   \n\n   in_response_to_tweet_id                                            text_pc  \\\n0                      3.0  115712 i understand i would like to assist you...   \n1                      1.0       sprintcare and how do you propose we do that   \n2                      4.0  sprintcare i have sent several private message...   \n3                      5.0  115712 please send us a private message so tha...   \n4                      6.0                                   sprintcare i did   \n5                      8.0  115712 can you please send us a private messag...   \n6                      NaN           sprintcare is the worst customer service   \n7                     12.0  115713 this is saddening to hear please shoot ...   \n8                     15.0  sprintcare you gonna magically change your con...   \n9                     16.0  115713 we understand your concerns and wed lik...   \n\n                                          text_pc_sl  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n5  115712 can you please send us a private messag...   \n6           sprintcare is the worst customer service   \n7  115713 this is saddening to hear please shoot ...   \n8  sprintcare you gonna magically change your con...   \n9  115713 we understand your concerns and wed lik...   \n\n                                       text_pc_sl_sw  \\\n0  115712  understand  would like  assist   would...   \n1                          sprintcare     propose      \n2  sprintcare   sent several private messages   o...   \n3  115712 please send us  private message      as...   \n4                                       sprintcare     \n5  115712   please send us  private message     g...   \n6                sprintcare   worst customer service   \n7  115713   saddening  hear please shoot us  dm  ...   \n8  sprintcare  gonna magically change  connectivi...   \n9  115713  understand  concerns  wed like    plea...   \n\n                                    text_pc_sl_sw_em  \n0  115712  understand  would like  assist   would...  \n1                          sprintcare     propose     \n2  sprintcare   sent several private messages   o...  \n3  115712 please send us  private message      as...  \n4                                       sprintcare    \n5  115712   please send us  private message     g...  \n6                sprintcare   worst customer service  \n7  115713   saddening  hear please shoot us  dm  ...  \n8  sprintcare  gonna magically change  connectivi...  \n9  115713  understand  concerns  wed like    plea...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n      <th>text_pc</th>\n      <th>text_pc_sl</th>\n      <th>text_pc_sl_sw</th>\n      <th>text_pc_sl_sw_em</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712  understand  would like  assist   would...</td>\n      <td>115712  understand  would like  assist   would...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcare     propose</td>\n      <td>sprintcare     propose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcare   sent several private messages   o...</td>\n      <td>sprintcare   sent several private messages   o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 please send us a private message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 please send us  private message      as...</td>\n      <td>115712 please send us  private message      as...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare i did.</td>\n      <td>4</td>\n      <td>6.0</td>\n      <td>sprintcare i did</td>\n      <td>sprintcare i did</td>\n      <td>sprintcare</td>\n      <td>sprintcare</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n      <td>@115712 can you please send us a private messa...</td>\n      <td>5,7</td>\n      <td>8.0</td>\n      <td>115712 can you please send us a private messag...</td>\n      <td>115712 can you please send us a private messag...</td>\n      <td>115712   please send us  private message     g...</td>\n      <td>115712   please send us  private message     g...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n      <td>@sprintcare is the worst customer service</td>\n      <td>9,6,10</td>\n      <td>NaN</td>\n      <td>sprintcare is the worst customer service</td>\n      <td>sprintcare is the worst customer service</td>\n      <td>sprintcare   worst customer service</td>\n      <td>sprintcare   worst customer service</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>11</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:35 +0000 2017</td>\n      <td>@115713 this is saddening to hear. please shoo...</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>115713 this is saddening to hear please shoot ...</td>\n      <td>115713 this is saddening to hear please shoot ...</td>\n      <td>115713   saddening  hear please shoot us  dm  ...</td>\n      <td>115713   saddening  hear please shoot us  dm  ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>12</td>\n      <td>115713</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:04:47 +0000 2017</td>\n      <td>@sprintcare you gonna magically change your co...</td>\n      <td>11,13,14</td>\n      <td>15.0</td>\n      <td>sprintcare you gonna magically change your con...</td>\n      <td>sprintcare you gonna magically change your con...</td>\n      <td>sprintcare  gonna magically change  connectivi...</td>\n      <td>sprintcare  gonna magically change  connectivi...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 20:03:31 +0000 2017</td>\n      <td>@115713 we understand your concerns and we'd l...</td>\n      <td>12</td>\n      <td>16.0</td>\n      <td>115713 we understand your concerns and wed lik...</td>\n      <td>115713 we understand your concerns and wed lik...</td>\n      <td>115713  understand  concerns  wed like    plea...</td>\n      <td>115713  understand  concerns  wed like    plea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Function to convert the Emoji's into Text ","metadata":{}},{"cell_type":"code","source":"pip install demoji","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:15:32.484129Z","iopub.execute_input":"2024-02-08T09:15:32.484537Z","iopub.status.idle":"2024-02-08T09:15:44.792946Z","shell.execute_reply.started":"2024-02-08T09:15:32.484507Z","shell.execute_reply":"2024-02-08T09:15:44.791562Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Collecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import demoji\ndemoji.download_codes()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:16:04.605285Z","iopub.execute_input":"2024-02-08T09:16:04.605810Z","iopub.status.idle":"2024-02-08T09:16:04.618714Z","shell.execute_reply.started":"2024-02-08T09:16:04.605754Z","shell.execute_reply":"2024-02-08T09:16:04.616443Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2319952594.py:2: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n  demoji.download_codes()\n","output_type":"stream"}]},{"cell_type":"code","source":"import emoji","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emoj(text):\n    clean_text = demoji.findall(text)\n    return(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:17:25.466447Z","iopub.execute_input":"2024-02-08T09:17:25.466840Z","iopub.status.idle":"2024-02-08T09:17:25.474193Z","shell.execute_reply.started":"2024-02-08T09:17:25.466808Z","shell.execute_reply":"2024-02-08T09:17:25.472127Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"## Applying the Punctuation free function for the \ndf['text_pc_sl_sw_em'] =  df['text_pc_sl_sw'].apply(lambda x: remove_emoj(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:17:31.930583Z","iopub.execute_input":"2024-02-08T09:17:31.930962Z","iopub.status.idle":"2024-02-08T09:20:47.557424Z","shell.execute_reply.started":"2024-02-08T09:17:31.930935Z","shell.execute_reply":"2024-02-08T09:20:47.556278Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Lemmatization ","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:21:19.866225Z","iopub.execute_input":"2024-02-08T09:21:19.866612Z","iopub.status.idle":"2024-02-08T09:21:19.872658Z","shell.execute_reply.started":"2024-02-08T09:21:19.866585Z","shell.execute_reply":"2024-02-08T09:21:19.870834Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def stemmings(text):\n    obj = PorterStemmer()\n    \n    stem_words = [obj.stem(word) for word in text.split()]\n    return stem_words","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:21:21.028641Z","iopub.execute_input":"2024-02-08T09:21:21.029004Z","iopub.status.idle":"2024-02-08T09:21:21.036302Z","shell.execute_reply.started":"2024-02-08T09:21:21.028976Z","shell.execute_reply":"2024-02-08T09:21:21.033976Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#applying function to the column\ndf['text_token_stem']= df['text_pc_sl_sw_em'].apply(lambda x: stemmings(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:21:25.924983Z","iopub.execute_input":"2024-02-08T09:21:25.926039Z","iopub.status.idle":"2024-02-08T09:34:12.702357Z","shell.execute_reply.started":"2024-02-08T09:21:25.925996Z","shell.execute_reply":"2024-02-08T09:34:12.700805Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization ","metadata":{"execution":{"iopub.status.busy":"2024-02-07T05:03:06.748660Z","iopub.execute_input":"2024-02-07T05:03:06.749132Z","iopub.status.idle":"2024-02-07T05:03:06.786680Z","shell.execute_reply.started":"2024-02-07T05:03:06.749093Z","shell.execute_reply":"2024-02-07T05:03:06.785423Z"}}},{"cell_type":"code","source":"import nltk \nfrom nltk import word_tokenize,sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:13:41.032222Z","iopub.status.idle":"2024-02-08T09:13:41.032854Z","shell.execute_reply.started":"2024-02-08T09:13:41.032565Z","shell.execute_reply":"2024-02-08T09:13:41.032587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#applying function to the column\ndf['text_token']= df['text_token_stem'].apply(lambda x: word_tokenize(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:13:41.034655Z","iopub.status.idle":"2024-02-08T09:13:41.035277Z","shell.execute_reply.started":"2024-02-08T09:13:41.035012Z","shell.execute_reply":"2024-02-08T09:13:41.035038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}